{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import uniform\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import sklearn\n",
    "import math\n",
    "from scipy import stats\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, LeaveOneGroupOut, StratifiedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFpr, SelectFwe, RFECV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV, LogisticRegression, SGDClassifier, LogisticRegressionCV, LarsCV, LassoLarsCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT CROSS-SITE TEST RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD_1\n",
      "FOLD_2\n",
      "FOLD_3\n",
      "FOLD_4\n",
      "FOLD_5\n"
     ]
    }
   ],
   "source": [
    "for direct in listdir(re.sub(\"RESULTS\",\"\",getcwd())):\n",
    "    if \"FOLD\" in direct:\n",
    "       \n",
    "        print(direct)\n",
    "    \n",
    "        # DEFINE CORRECT PATH FOR IMPORTING\n",
    "        directory_this = re.sub(\"RESULTS\",\"\",getcwd())+direct+\"/files\"\n",
    "        \n",
    "        # IMPORT IDs OF TEST CASES\n",
    "        globals()[\"id_test_\"+re.sub(\"[^0-9]\", \"\", direct)] = pd.read_csv(directory_this+'/id_test.csv', sep=',',header=None)\n",
    "        \n",
    "        # IMPORT TRUE OBSERVED OUTCOME OF TEST CASES\n",
    "        globals()[\"true_outcome_test_\"+re.sub(\"[^0-9]\", \"\", direct)] = pd.read_csv(directory_this+'/true_outcome_test.csv', sep=',',header=None)\n",
    "        \n",
    "        # IMPORT PROBABILISTIC PREDICTIONS OF TEST CASES WRA\n",
    "        globals()[\"probabilistic_prediction_test_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"] = pd.read_csv(directory_this+'/probabilistic_prediction_test_wra.csv', sep=',',header=None)\n",
    "        \n",
    "        # IMPORT CATEGORICAL PREDICTIONS (BEST BALANCED ACCURACY) OUTCOME OF TEST CASES WRA\n",
    "        globals()[\"categorical_outcome_test_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"] = pd.read_csv(directory_this+'/categorical_outcome_test_wra.csv', sep=',',header=None)\n",
    "\n",
    "        # IMPORT ROC OF TEST CASES WRA\n",
    "        globals()[\"roc_test_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"] = pd.read_csv(directory_this+'/roc_test_wra.csv', sep=',',header=None)\n",
    "\n",
    "        # IMPORT THRESHOLD FOR BEST BALANCED ACCURACY OF TEST CASES WRA\n",
    "        globals()[\"t_best_balanced_accuracy_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"] = pd.read_csv(directory_this+'/t_best_balanaced_accuracy_wra.csv', sep=',',header=None)\n",
    "\n",
    "        # IMPORT RESULTS OF THRESHOLD FOR OTHER SENSITIVITY LEVELS OF TEST CASES WRA\n",
    "        globals()[\"t_moving_results_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"] = pd.read_csv(directory_this+'/t_moving_results_wra.csv', sep=',',header=None)\n",
    "\n",
    "        # EXTRACT THRESHOLD FOR OTHER SENSITIVITY LEVELS OF TEST CASES WRA\n",
    "        for i in range(globals()[\"t_moving_results_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"].shape[0]):\n",
    "            globals()[\"t_sensitivity_\"+str(globals()[\"t_moving_results_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"].iloc[i,0])+\"_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"] = globals()[\"t_moving_results_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"].loc[i,1]\n",
    "        \n",
    "        # IMPORT CATEGORICAL PREDICTIONS FOR OTHER SENSITIVITY LEVELS OF TEST CASES WRA\n",
    "        for i in range(globals()[\"t_moving_results_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"].shape[0]):\n",
    "            globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"].iloc[i,0])+\"_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"] = pd.read_csv(directory_this+\"/categor_moving_sensitivity_outcome_test_\"+str(globals()[\"t_moving_results_\"+re.sub(\"[^0-9]\", \"\", direct)+\"_wra\"].iloc[i,0])+\"_wra.csv\", sep=',',header=None)\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK THAT ALL CASES HAVE BEEN TESTED (N TOT = 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n"
     ]
    }
   ],
   "source": [
    "objects = list(globals())\n",
    "\n",
    "# CHECK IDs\n",
    "summa = 0\n",
    "for obj in objects:\n",
    "    if \"id_test\" in obj:\n",
    "        summa += len(globals()[obj])\n",
    "print(summa)\n",
    "\n",
    "# CHECK TRUE OBSERVED\n",
    "summa = 0\n",
    "for obj in objects:\n",
    "    if \"true_outcome\" in obj:\n",
    "        summa += len(globals()[obj])\n",
    "print(summa)\n",
    "\n",
    "# CHECK PROBABILISTIC PREDICTIONS WRA\n",
    "summa = 0\n",
    "for obj in objects:\n",
    "    if \"probabilistic_prediction\" in obj and \"wra\" in obj:\n",
    "        summa += len(globals()[obj])\n",
    "print(summa)\n",
    "\n",
    "# CHECK CATEGORICAL PREDICTIONS (BEST BALANCED ACCURACY) WRA\n",
    "summa = 0\n",
    "for obj in objects:\n",
    "    if \"categorical_outcome\" in obj and \"wra\" in obj:\n",
    "        summa += len(globals()[obj])\n",
    "print(summa)\n",
    "\n",
    "# CHECK CATEGORICAL PREDICTIONS (SENSITIVITY LEVELS) WRA\n",
    "for i in range(globals()[\"t_moving_results_1_wra\"].shape[0]):\n",
    "    summa = 0\n",
    "    for obj in objects:\n",
    "        if \"categor_outcome\" in obj and \"wra\" in obj and str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_\" in obj:\n",
    "            summa += len(globals()[obj])\n",
    "    print(summa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE THE TEST RESULTS, AND CHECK THAT THE DIMENSION IS CORRECT (N=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "(550,)\n",
      "0.58874\n",
      "0.25338\n",
      "0.29436\n",
      "0.32068\n",
      "0.35074\n",
      "0.45856\n",
      "0.50886\n",
      "0.58214\n",
      "0.62716\n"
     ]
    }
   ],
   "source": [
    "objects = list(globals())\n",
    "\n",
    "# MERGE IDs\n",
    "id_test_complete = []\n",
    "for obj in objects:\n",
    "    if \"id_test\" in obj:\n",
    "        id_test_complete = np.append(id_test_complete, globals()[obj])\n",
    "print(id_test_complete.shape)\n",
    "\n",
    "# MERGE THE FOLD NUMBER\n",
    "fold_number = []\n",
    "for obj in objects:\n",
    "    if \"id_test\" in obj:\n",
    "        fold_this = np.repeat(re.sub(\"id_test_\",\"\",obj),globals()[obj].shape[0])\n",
    "        fold_number = np.append(fold_number, fold_this)\n",
    "print(fold_number.shape)\n",
    "\n",
    "# MERGE TRUE OBSERVED\n",
    "true_outcome_complete = []\n",
    "for obj in objects:\n",
    "    if \"true_outcome\" in obj:\n",
    "        true_outcome_complete = np.append(true_outcome_complete, globals()[obj])\n",
    "print(true_outcome_complete.shape)\n",
    "\n",
    "# MERGE PROBABILISTIC PREDICTIONS WRA\n",
    "probabilistic_prediction_complete_wra = []\n",
    "for obj in objects:\n",
    "    if \"probabilistic_prediction\" in obj and \"wra\" in obj:\n",
    "        probabilistic_prediction_complete_wra = np.append(probabilistic_prediction_complete_wra, globals()[obj])\n",
    "print(probabilistic_prediction_complete_wra.shape)\n",
    "\n",
    "# MERGE CATEGORICAL PREDICTIONS (BEST BALANCED ACCURACY) WRA\n",
    "categorical_outcome_complete_wra = []\n",
    "for obj in objects:\n",
    "    if \"categorical_outcome\" in obj and \"wra\" in obj:\n",
    "        categorical_outcome_complete_wra = np.append(categorical_outcome_complete_wra, globals()[obj])\n",
    "print(categorical_outcome_complete_wra.shape)\n",
    "\n",
    "# MERGE CATEGORICAL PREDICTIONS (SENSITIVITY LEVELS) WRA\n",
    "for i in range(globals()[\"t_moving_results_1_wra\"].shape[0]):\n",
    "    globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"] = []\n",
    "    for obj in objects:\n",
    "        if \"categor_outcome\" in obj and \"wra\" in obj and str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_\" in obj:\n",
    "            globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"] = np.append(globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"], globals()[obj])\n",
    "    print(globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"].shape)\n",
    "    \n",
    "# AVERAGE THRESHOLDS (BEST BALANCED ACCURACY) WRA\n",
    "t_average_best_balanced_wra = 0.\n",
    "count=0\n",
    "for obj in objects:\n",
    "    if \"t_best_balanced\" in obj and \"wra\" in obj:\n",
    "        t_average_best_balanced_wra += globals()[obj].iloc[0,0]\n",
    "        count+=1\n",
    "t_average_best_balanced_wra /= count\n",
    "print(t_average_best_balanced_wra)\n",
    "    \n",
    "# AVERAGE THRESHOLDS (SENSITIVITY LEVELS) WRA\n",
    "for i in range(globals()[\"t_moving_results_1_wra\"].shape[0]):\n",
    "    globals()[\"t_average_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"] = 0\n",
    "    count=0\n",
    "    for obj in objects:\n",
    "        if \"t_sensitivity\" in obj and \"wra\" in obj and str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_\" in obj:\n",
    "            globals()[\"t_average_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"] += globals()[obj]\n",
    "            count +=1\n",
    "    globals()[\"t_average_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"] /= count\n",
    "    print(globals()[\"t_average_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST IT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEIGHTED RANK AVERAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### WHOLE TEST SAMPLE \n",
      " \n",
      "AVERAGE TEST AUCROC SCORE: 0.8842278900391307\n",
      "POOLED TEST AUCROC SCORE: 0.880315209732\n",
      "     \n",
      "_______________________________________________\n",
      "     \n",
      "TEST CATEGORICAL THRESHOLD APPLIED WITHIN TRAIN SPLIT\n",
      " \n",
      "RESULTS OF BEST BALANCED ACCURACY\n",
      "BALANCED ACCURACY:                   0.785515019916\n",
      "F1-SCORE:                            0.724220623501\n",
      "SENSITIVITY/RECALL:                  0.766497461929\n",
      "SPECIFICITY:                         0.804532577904\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.686363636364\n",
      "NEGATIVE PREDICTIVE VALUE:           0.860606060606\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 1.0\n",
      "BALANCED ACCURACY:                   0.694345781625\n",
      "F1-SCORE:                            0.645799011532\n",
      "SENSITIVITY/RECALL:                  0.994923857868\n",
      "SPECIFICITY:                         0.393767705382\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.478048780488\n",
      "NEGATIVE PREDICTIVE VALUE:           0.992857142857\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.99\n",
      "BALANCED ACCURACY:                   0.715887030673\n",
      "F1-SCORE:                            0.662139219015\n",
      "SENSITIVITY/RECALL:                  0.989847715736\n",
      "SPECIFICITY:                         0.441926345609\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.497448979592\n",
      "NEGATIVE PREDICTIVE VALUE:           0.987341772152\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.975\n",
      "BALANCED ACCURACY:                   0.728692426051\n",
      "F1-SCORE:                            0.671378091873\n",
      "SENSITIVITY/RECALL:                  0.964467005076\n",
      "SPECIFICITY:                         0.492917847025\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.514905149051\n",
      "NEGATIVE PREDICTIVE VALUE:           0.961325966851\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.95\n",
      "BALANCED ACCURACY:                   0.73978660071\n",
      "F1-SCORE:                            0.680073126143\n",
      "SENSITIVITY/RECALL:                  0.944162436548\n",
      "SPECIFICITY:                         0.535410764873\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.531428571429\n",
      "NEGATIVE PREDICTIVE VALUE:           0.945\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.9\n",
      "BALANCED ACCURACY:                   0.78268934873\n",
      "F1-SCORE:                            0.720164609053\n",
      "SENSITIVITY/RECALL:                  0.888324873096\n",
      "SPECIFICITY:                         0.677053824363\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.60553633218\n",
      "NEGATIVE PREDICTIVE VALUE:           0.915708812261\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.85\n",
      "BALANCED ACCURACY:                   0.792424612818\n",
      "F1-SCORE:                            0.73127753304\n",
      "SENSITIVITY/RECALL:                  0.842639593909\n",
      "SPECIFICITY:                         0.742209631728\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.645914396887\n",
      "NEGATIVE PREDICTIVE VALUE:           0.894197952218\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.8\n",
      "BALANCED ACCURACY:                   0.781797788355\n",
      "F1-SCORE:                            0.719626168224\n",
      "SENSITIVITY/RECALL:                  0.781725888325\n",
      "SPECIFICITY:                         0.781869688385\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.666666666667\n",
      "NEGATIVE PREDICTIVE VALUE:           0.865203761755\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.75\n",
      "BALANCED ACCURACY:                   0.774593405329\n",
      "F1-SCORE:                            0.710659898477\n",
      "SENSITIVITY/RECALL:                  0.710659898477\n",
      "SPECIFICITY:                         0.838526912181\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.710659898477\n",
      "NEGATIVE PREDICTIVE VALUE:           0.838526912181\n",
      "     \n",
      "TEST CATEGORICAL WITH AVERAGE THRESHOLD APPLIED AFTER POOLING OF CONTINUOUS WRA PREDICTIONS\n",
      " \n",
      "RESULTS OF BEST BALANCED ACCURACY\n",
      "BALANCED ACCURACY:                   0.787758300858\n",
      "F1-SCORE:                            0.726840855107\n",
      "SENSITIVITY/RECALL:                  0.776649746193\n",
      "SPECIFICITY:                         0.798866855524\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.683035714286\n",
      "NEGATIVE PREDICTIVE VALUE:           0.865030674847\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 1.0\n",
      "BALANCED ACCURACY:                   0.701133144476\n",
      "F1-SCORE:                            0.651239669421\n",
      "SENSITIVITY/RECALL:                  1.0\n",
      "SPECIFICITY:                         0.402266288952\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.482843137255\n",
      "NEGATIVE PREDICTIVE VALUE:           1.0\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.99\n",
      "BALANCED ACCURACY:                   0.717893041515\n",
      "F1-SCORE:                            0.66323024055\n",
      "SENSITIVITY/RECALL:                  0.979695431472\n",
      "SPECIFICITY:                         0.456090651558\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.501298701299\n",
      "NEGATIVE PREDICTIVE VALUE:           0.975757575758\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.975\n",
      "BALANCED ACCURACY:                   0.735184998778\n",
      "F1-SCORE:                            0.677248677249\n",
      "SENSITIVITY/RECALL:                  0.97461928934\n",
      "SPECIFICITY:                         0.495750708215\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.518918918919\n",
      "NEGATIVE PREDICTIVE VALUE:           0.972222222222\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.95\n",
      "BALANCED ACCURACY:                   0.739491810587\n",
      "F1-SCORE:                            0.68\n",
      "SENSITIVITY/RECALL:                  0.94923857868\n",
      "SPECIFICITY:                         0.529745042493\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.529745042493\n",
      "NEGATIVE PREDICTIVE VALUE:           0.94923857868\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.9\n",
      "BALANCED ACCURACY:                   0.781272918135\n",
      "F1-SCORE:                            0.718685831622\n",
      "SENSITIVITY/RECALL:                  0.888324873096\n",
      "SPECIFICITY:                         0.674220963173\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.603448275862\n",
      "NEGATIVE PREDICTIVE VALUE:           0.915384615385\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.85\n",
      "BALANCED ACCURACY:                   0.786758890439\n",
      "F1-SCORE:                            0.724890829694\n",
      "SENSITIVITY/RECALL:                  0.842639593909\n",
      "SPECIFICITY:                         0.730878186969\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.63601532567\n",
      "NEGATIVE PREDICTIVE VALUE:           0.892733564014\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.8\n",
      "BALANCED ACCURACY:                   0.793956083462\n",
      "F1-SCORE:                            0.734117647059\n",
      "SENSITIVITY/RECALL:                  0.791878172589\n",
      "SPECIFICITY:                         0.796033994334\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.684210526316\n",
      "NEGATIVE PREDICTIVE VALUE:           0.872670807453\n",
      "     \n",
      "RESULTS OF SENSITIVITY LEVEL 0.75\n",
      "BALANCED ACCURACY:                   0.77854790699\n",
      "F1-SCORE:                            0.715736040609\n",
      "SENSITIVITY/RECALL:                  0.715736040609\n",
      "SPECIFICITY:                         0.841359773371\n",
      "POSITIVE PREDICTIVE VALUE/PRECISION: 0.715736040609\n",
      "NEGATIVE PREDICTIVE VALUE:           0.841359773371\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "# WHOLE TEST SAMPLE\n",
    "\n",
    "print(\"### WHOLE TEST SAMPLE \")\n",
    "print(\" \")\n",
    "\n",
    "prediction_BEST_MODEL = probabilistic_prediction_complete_wra\n",
    "y_test = true_outcome_complete\n",
    "\n",
    "objects = list(globals())\n",
    "mean_roc = 0\n",
    "count = 0\n",
    "for obj in objects:\n",
    "    if \"roc_test\" in obj and \"wra\" in obj:\n",
    "        mean_roc += globals()[obj]\n",
    "        count += 1\n",
    "mean_roc = mean_roc / count\n",
    "mean_roc = float(np.array(mean_roc))\n",
    "\n",
    "# print(\"TEST AUCROC SCORE: \"+str(roc_auc_score(y_true = y_test, y_score=prediction_BEST_MODEL)))\n",
    "print(\"AVERAGE TEST AUCROC SCORE: \"+str(mean_roc))\n",
    "print(\"POOLED TEST AUCROC SCORE: \"+str(roc_auc_score(y_true = y_test, y_score=prediction_BEST_MODEL)))\n",
    "print(\"     \")\n",
    "print(\"_______________________________________________\")\n",
    "print(\"     \")\n",
    "\n",
    "print(\"TEST CATEGORICAL THRESHOLD APPLIED WITHIN TRAIN SPLIT\")\n",
    "print(\" \")\n",
    "\n",
    "index_converters_test = np.where(y_test ==1)\n",
    "index_non_converters_test = np.where(y_test ==0)\n",
    "index_pred_pos_test = np.where(categorical_outcome_complete_wra == 1)\n",
    "index_pred_neg_test = np.where(categorical_outcome_complete_wra == 0)\n",
    "\n",
    "sens_test = sum(categorical_outcome_complete_wra[index_converters_test] == 1) / sum(y_test == 1)\n",
    "spec_test = sum(categorical_outcome_complete_wra[index_non_converters_test] == 0) / sum(y_test == 0)\n",
    "ppv_test = sum(y_test[index_pred_pos_test] == 1) / sum(categorical_outcome_complete_wra == 1)\n",
    "npv_test = sum(y_test[index_pred_neg_test] == 0) / sum(categorical_outcome_complete_wra == 0)\n",
    "\n",
    "print(\"RESULTS OF BEST BALANCED ACCURACY\")\n",
    "print(\"BALANCED ACCURACY:                   \"+ str((sens_test+spec_test)/2))\n",
    "print(\"F1-SCORE:                            \"+ str(2*ppv_test*sens_test/(ppv_test+sens_test)))\n",
    "print(\"SENSITIVITY/RECALL:                  \"+ str(sens_test))\n",
    "print(\"SPECIFICITY:                         \"+ str(spec_test))\n",
    "print(\"POSITIVE PREDICTIVE VALUE/PRECISION: \"+ str(ppv_test))\n",
    "print(\"NEGATIVE PREDICTIVE VALUE:           \"+ str(npv_test))\n",
    "print(\"     \")\n",
    "\n",
    "for i in range(globals()[\"t_moving_results_1_wra\"].shape[0]):\n",
    "    \n",
    "    index_converters_test = np.where(y_test ==1)\n",
    "    index_non_converters_test = np.where(y_test ==0)\n",
    "    index_pred_pos_test = np.where(globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"] == 1)\n",
    "    index_pred_neg_test = np.where(globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"] == 0)\n",
    "\n",
    "    sens_test = sum(globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"][index_converters_test] == 1) / sum(y_test == 1)\n",
    "    spec_test = sum(globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"][index_non_converters_test] == 0) / sum(y_test == 0)\n",
    "    ppv_test = sum(y_test[index_pred_pos_test] == 1) / sum(globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"] == 1)\n",
    "    npv_test = sum(y_test[index_pred_neg_test] == 0) / sum(globals()[\"categor_outcome_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0])+\"_wra\"] == 0)\n",
    "\n",
    "    print(\"RESULTS OF SENSITIVITY LEVEL \"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0]))\n",
    "    print(\"BALANCED ACCURACY:                   \"+ str((sens_test+spec_test)/2))\n",
    "    print(\"F1-SCORE:                            \"+ str(2*ppv_test*sens_test/(ppv_test+sens_test)))\n",
    "    print(\"SENSITIVITY/RECALL:                  \"+ str(sens_test))\n",
    "    print(\"SPECIFICITY:                         \"+ str(spec_test))\n",
    "    print(\"POSITIVE PREDICTIVE VALUE/PRECISION: \"+ str(ppv_test))\n",
    "    print(\"NEGATIVE PREDICTIVE VALUE:           \"+ str(npv_test))\n",
    "    print(\"     \")\n",
    "\n",
    "print(\"TEST CATEGORICAL WITH AVERAGE THRESHOLD APPLIED AFTER POOLING OF CONTINUOUS WRA PREDICTIONS\") \n",
    "print(\" \")\n",
    "\n",
    "t = t_average_best_balanced_wra\n",
    "\n",
    "index_converters_test = np.where(y_test ==1)\n",
    "index_non_converters_test = np.where(y_test ==0)\n",
    "\n",
    "sens_test = sum(prediction_BEST_MODEL[index_converters_test] >= t) / prediction_BEST_MODEL[index_converters_test].shape[0]\n",
    "spec_test = sum(prediction_BEST_MODEL[index_non_converters_test] < t) / prediction_BEST_MODEL[index_non_converters_test].shape[0]\n",
    "ppv_test = sum(prediction_BEST_MODEL[index_converters_test] >= t) / sum(prediction_BEST_MODEL >= t)\n",
    "npv_test = sum(prediction_BEST_MODEL[index_non_converters_test] < t) / sum(prediction_BEST_MODEL < t)\n",
    "\n",
    "print(\"RESULTS OF BEST BALANCED ACCURACY\")\n",
    "print(\"BALANCED ACCURACY:                   \"+ str((sens_test+spec_test)/2))\n",
    "print(\"F1-SCORE:                            \"+ str(2*ppv_test*sens_test/(ppv_test+sens_test)))\n",
    "print(\"SENSITIVITY/RECALL:                  \"+ str(sens_test))\n",
    "print(\"SPECIFICITY:                         \"+ str(spec_test))\n",
    "print(\"POSITIVE PREDICTIVE VALUE/PRECISION: \"+ str(ppv_test))\n",
    "print(\"NEGATIVE PREDICTIVE VALUE:           \"+ str(npv_test))\n",
    "print(\"     \")\n",
    "\n",
    "for i in range(globals()[\"t_moving_results_1_wra\"].shape[0]):\n",
    "    \n",
    "    t = globals()[\"t_average_sensitivity_\"+str(globals()[\"t_moving_results_1_wra\"].iloc[i,0])+\"_wra\"]\n",
    "\n",
    "    index_converters_test = np.where(y_test ==1)\n",
    "    index_non_converters_test = np.where(y_test ==0)\n",
    "\n",
    "    sens_test = sum(prediction_BEST_MODEL[index_converters_test] >= t) / prediction_BEST_MODEL[index_converters_test].shape[0]\n",
    "    spec_test = sum(prediction_BEST_MODEL[index_non_converters_test] < t) / prediction_BEST_MODEL[index_non_converters_test].shape[0]\n",
    "    ppv_test = sum(prediction_BEST_MODEL[index_converters_test] >= t) / sum(prediction_BEST_MODEL >= t)\n",
    "    npv_test = sum(prediction_BEST_MODEL[index_non_converters_test] < t) / sum(prediction_BEST_MODEL < t)\n",
    "\n",
    "    print(\"RESULTS OF SENSITIVITY LEVEL \"+str(globals()[\"t_moving_results_1_wra\"].loc[i,0]))\n",
    "    print(\"BALANCED ACCURACY:                   \"+ str((sens_test+spec_test)/2))\n",
    "    print(\"F1-SCORE:                            \"+ str(2*ppv_test*sens_test/(ppv_test+sens_test)))\n",
    "    print(\"SENSITIVITY/RECALL:                  \"+ str(sens_test))\n",
    "    print(\"SPECIFICITY:                         \"+ str(spec_test))\n",
    "    print(\"POSITIVE PREDICTIVE VALUE/PRECISION: \"+ str(ppv_test))\n",
    "    print(\"NEGATIVE PREDICTIVE VALUE:           \"+ str(npv_test))\n",
    "    print(\"     \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number.tofile('fold_number.csv')\n",
    "np.savetxt('true_outcome_complete.csv', true_outcome_complete, delimiter=\",\")\n",
    "np.savetxt('probabilistic_prediction_complete_wra.csv', probabilistic_prediction_complete_wra, delimiter=\",\")\n",
    "np.savetxt('categorical_outcome_complete_wra.csv', categorical_outcome_complete_wra, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POOLED UNIVARIATE FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD_1\n",
      "FOLD_2\n",
      "FOLD_3\n",
      "FOLD_4\n",
      "FOLD_5\n"
     ]
    }
   ],
   "source": [
    "for direct in listdir(re.sub(\"RESULTS\",\"\",getcwd())):\n",
    "    if \"FOLD\" in direct:\n",
    "\n",
    "        print(direct)   \n",
    "        \n",
    "        # DEFINE CORRECT PATH FOR IMPORTING\n",
    "        directory_this = re.sub(\"RESULTS\",\"\",getcwd())+direct+\"/univariate_feature_importance\"\n",
    "        for file in listdir(directory_this):\n",
    "            if \"prediction_test\" in file:\n",
    "                \n",
    "                # IMPORT UNIVARIATE FEATURE PREDICTIONS OF THAT TEST FOLD\n",
    "                globals()[re.sub(\".csv\",\"\",file)] = pd.read_csv(directory_this+\"/\"+file, sep=',',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE POOLED UNIVARIATE FEATURE IMPORTANCE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature:  AGE   550\n",
      "feature:  CDRSB   550\n",
      "feature:  DX_bl   550\n",
      "feature:  FAQ   550\n",
      "feature:  LDELTOTAL   550\n",
      "feature:  MMSE   550\n",
      "feature:  PCA_1_ADAS   550\n",
      "feature:  PCA_1_RAVLT_forgetting   550\n",
      "feature:  PTEDUCAT   550\n",
      "feature:  PTGENDER   550\n",
      "feature:  PTMARRY_Divorced   550\n",
      "feature:  PTMARRY_Married   550\n",
      "feature:  PTMARRY_Never married   550\n",
      "feature:  PTMARRY_Widowed   550\n",
      "feature:  RAVLT_immediate   550\n",
      "feature:  RAVLT_learning   550\n",
      "feature:  TRABSCOR   550\n"
     ]
    }
   ],
   "source": [
    "objects = list(globals())\n",
    "\n",
    "# FIND VARIABLE NAMES\n",
    "feature_names = []\n",
    "\n",
    "for obj in objects:\n",
    "    if \"prediction_test_UNIVARIATE_FEATURE_IMPORTANCE_\" in obj:\n",
    "        feature_names.append(re.sub(\"prediction_test_UNIVARIATE_FEATURE_IMPORTANCE_\",\"\",re.sub(\"_[0-9]\",\"\",obj)))\n",
    "        # feature_names.append(re.sub(\"prediction_test_UNIVARIATE_FEATURE_IMPORTANCE_\",\"\",obj))\n",
    "\n",
    "feature_names = [i for i in np.unique(feature_names)]\n",
    "\n",
    "# MERGE PREDICTIONS FOR EACH FEATURE\n",
    "for feature in feature_names:\n",
    "    if \"PCA\" in feature:\n",
    "        feature = re.sub(\"PCA_\",\"PCA_1_\",feature)\n",
    "\n",
    "    prediction_this = np.array([])   \n",
    "    summa = 0\n",
    "    for obj in objects:\n",
    "        if feature in obj and \"prediction_test_UNIVARIATE_FEATURE_IMPORTANCE_\" in obj:\n",
    "            prediction_this = np.append(prediction_this, np.array(globals()[obj]).tolist())\n",
    "            summa += len(globals()[obj])\n",
    "    globals()[\"prediction_test_UNIVARIATE_FEATURE_IMPORTANCE_complete_\"+feature] = prediction_this\n",
    "    print(\"feature: \", feature, \" \",summa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>Pooled_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA_1_ADAS</td>\n",
       "      <td>0.808933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RAVLT_immediate</td>\n",
       "      <td>0.777124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FAQ</td>\n",
       "      <td>0.776887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDELTOTAL</td>\n",
       "      <td>0.76956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RAVLT_learning</td>\n",
       "      <td>0.707094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDRSB</td>\n",
       "      <td>0.696546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA_1_RAVLT_forgetting</td>\n",
       "      <td>0.685236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MMSE</td>\n",
       "      <td>0.678197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DX_bl</td>\n",
       "      <td>0.657662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TRABSCOR</td>\n",
       "      <td>0.657634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.564487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PTEDUCAT</td>\n",
       "      <td>0.539725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PTMARRY_Married</td>\n",
       "      <td>0.505694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTMARRY_Divorced</td>\n",
       "      <td>0.50115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PTMARRY_Widowed</td>\n",
       "      <td>0.487626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PTMARRY_Never married</td>\n",
       "      <td>0.486691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PTGENDER</td>\n",
       "      <td>0.475425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   FEATURE Pooled_AUC\n",
       "6               PCA_1_ADAS   0.808933\n",
       "14         RAVLT_immediate   0.777124\n",
       "3                      FAQ   0.776887\n",
       "4                LDELTOTAL    0.76956\n",
       "15          RAVLT_learning   0.707094\n",
       "1                    CDRSB   0.696546\n",
       "7   PCA_1_RAVLT_forgetting   0.685236\n",
       "5                     MMSE   0.678197\n",
       "2                    DX_bl   0.657662\n",
       "16                TRABSCOR   0.657634\n",
       "0                      AGE   0.564487\n",
       "8                 PTEDUCAT   0.539725\n",
       "11         PTMARRY_Married   0.505694\n",
       "10        PTMARRY_Divorced    0.50115\n",
       "13         PTMARRY_Widowed   0.487626\n",
       "12   PTMARRY_Never married   0.486691\n",
       "9                 PTGENDER   0.475425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CREATE DATAFRAME OF RESULTS\n",
    "UNIVARIATE_FEATURE_IMPORTANCE = pd.DataFrame(np.array([\"\",0,\"\",0]).reshape((2,2)), columns= [\"FEATURE\",\"Pooled_AUC\"])\n",
    "y_test = true_outcome_complete\n",
    "\n",
    "# CALCULATE RESULTS AND INPUT THEM IN THE DATAFRAME\n",
    "count = 0\n",
    "for feature in feature_names:\n",
    "    if \"PCA\" in feature:\n",
    "        feature = re.sub(\"PCA_\",\"PCA_1_\",feature)\n",
    "    \n",
    "    # CALCULATE THE AUROC\n",
    "    roc_this = roc_auc_score(y_true = y_test, y_score = globals()[\"prediction_test_UNIVARIATE_FEATURE_IMPORTANCE_complete_\"+feature] )\n",
    "    \n",
    "    # UPDATE THE DATAFRAME OF REULTS\n",
    "    UNIVARIATE_FEATURE_IMPORTANCE.loc[count] = [feature,roc_this]\n",
    "    count +=1\n",
    "\n",
    "# PRINT THE RESULTS\n",
    "display(UNIVARIATE_FEATURE_IMPORTANCE.sort_values(by=\"Pooled_AUC\", ascending=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT FOR BOOSTRAP CI CALCULATION IN R\n",
    "for object in list(globals()):\n",
    "    if \"prediction_test_UNIVARIATE_FEATURE_IMPORTANCE_complete_\" in object:\n",
    "        np.savetxt(\"probabilistic_\"+object+\".csv\", globals()[object], delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
